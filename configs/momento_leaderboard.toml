# An example configuration for benchmarking Momento (https://www.gomomento.com)
# leaderboards.

[general]
# specify the protocol to be used
protocol = "momento"
# the interval for stats integration and reporting
interval = 60
# the number of intervals to run the test for
duration = 300
# run the admin thread with a HTTP listener at the address provided, this allows
# stats exposition via HTTP
admin = "127.0.0.1:9090"
# optionally, set an initial seed for the PRNGs used to generate the workload.
# The default is to intialize from the OS entropy pool.
#initial_seed = "0"

#[metrics]
# output file for detailed stats during the run
#output = "stats.json"
# format of the output file (possible values are json, msgpack, parquet)
#format = "json"
# optionally specify batch size for parquet row groups
# only valid for parquet output
#batch_size = 100_000
# optionally specify histogram type (can be standard (default) or sparse)
# only valid for parquet output
#histogram = "sparse"
# optionally, specify the sampling interval for metrics. Input is a string
# with the unit attached; for example "100ms" or "1s". Defaults to 1s.
#interval = "1s"

[debug]
# choose from: error, warn, info, debug, trace
log_level = "info"
# optionally, log to the file below instead of standard out
# log_file = "rpc-perf.log"
# backup file name for use with log rotation
log_backup = "rpc-perf.log.old"
# trigger log rotation when the file grows beyond this size (in bytes). Set this
# option to '0' to disable log rotation.
log_max_size = 1073741824

[target]
# we don't need to specify any endpoints for momento
endpoints = []
# specify the name of the target cache for the leaderboard
cache_name = "test-cache"

[leaderboard]
# number of threads used to drive client requests
threads = 1
# number of gRPC clients to initialize, each maintains at least one TCP stream
poolsize = 1
# an upper limit on the number of concurrent requests per gRPC client
concurrency = 20
# set the timeout in milliseconds
request_timeout = 1000

[workload]
# the number of threads that will be used to generate the workload
threads = 1

[workload.ratelimit]
# set a global ratelimit for the workload
start = 50

[[workload.leaderboard]]
weight = 1
# Number of distinct leaderboards to create
nleaderboards = 1
# Number of distinct ids to use across all leaderboards
nids = 100

# run upsert vs get_competition_rank in a 10:1 ratio
# each time, only upsert/query a single id
commands = [
	{ verb = "upsert", weight = 10, cardinality = 1 },
	{ verb = "get_competition_rank", weight = 1, cardinality = 1 },
]
