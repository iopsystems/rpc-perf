# An example configuration for benchmarking Pelikan Segcache with an 80/20
# read/write mix in a keyspace of 1M keys using 32B keys and 128B values.

[general]
# specify the protocol to be used
protocol = "memcache"
# the interval for stats integration and reporting
interval = 60
# the number of intervals to run the test for
duration = 300
# run the admin thread with a HTTP listener at the address provided, this allows
# stats exposition via HTTP
admin = "127.0.0.1:9090"
# optionally, set an initial seed for the PRNGs used to generate the workload.
# The default is to intialize from the OS entropy pool.
#initial_seed = "0"

[metrics]
# output file for detailed stats during the run
#output = "stats.json"
# format of the output file (possible values are json, msgpack, parquet)
#format = "json"
# optionally specify batch size for parquet row groups
# only valid for parquet output
#batch_size = 100_000
# optionally specify histogram type (can be standard (default) or sparse)
# only valid for parquet output
#histogram = "sparse"
# optionally, specify the sampling interval for metrics. Input is a string
# with the unit attached; for example "100ms" or "1s". Default to 100ms.
#interval = "1s"

[debug]
# choose from: error, warn, info, debug, trace
log_level = "info"
# optionally, log to the file below instead of standard out
# log_file = "rpc-perf.log"
# backup file name for use with log rotation
log_backup = "rpc-perf.log.old"
# trigger log rotation when the file grows beyond this size (in bytes). Set this
# option to '0' to disable log rotation.
log_max_size = 1073741824

[target]
# specify one or more endpoints as IP:PORT pairs
endpoints = [
	"127.0.0.1:12321",
]

[client]
# number of threads used to drive client requests
threads = 4
# the total number of connections to each endpoint
poolsize = 20
# the connect timeout in milliseconds
connect_timeout = 10000
# set the timeout in milliseconds
request_timeout = 1000

[workload]
# the number of threads that will be used to generate the workload
threads = 1

[workload.ratelimit]
# set a global ratelimit for the workload. If an end is also specified,
# this is the start point of the ramp.
start = 10_000
# the end of the ramp. If this is not specified, the start rate is held
# constant through the run.
#end = 100_000
# the step function to be used during the ramp. optional, but must be
# provided if the end is specified.
#step = 5_000
# time to wait at each step of the ramp. optional, but must be provided if
# and end is specified.
#interval = 10
# type of ramp function. possible values are (linear, shuffled)
#ramp = "linear"
# behaviour once the ramp is completed. options are:
#   - stable: stays at the final value of the ramp until completion
#   - loop: restarts the ramp from the start value
#   - mirror: restarts the ramp in the opposite direction, i.e., from the end
#on_ramp_completion = "stable"

[[workload.keyspace]]
# sets the relative weight of this keyspace: defaults to 1
weight = 1
# sets the length of the key, in bytes
klen = 32
# sets the number of keys that will be generated
nkeys = 1_000_000
# sets the value length, in bytes
vlen = 128
# use random bytes for the values
vkind = "bytes"
# optionally, specify an approximate compression ratio for the value payload.
# Defaults to 1.0 meaning the message is high-entropy and not compressible.
compression_ratio = 1.0
# controls what commands will be used in this keyspace
commands = [
	# get a value
	{ verb = "get", weight = 80 },
	# set a value
	{ verb = "set", weight = 20 },
	# delete a value
	{ verb = "delete", weight = 0 },
]

# To enable mTLS, uncomment the `[tls]` section below.

#[tls]
# set the client's TLS private key for mTLS authentication
#private_key = "path/to/client_key.pem"
# set the client's TLS certificate for mTLS authentication
#certificate = "path/to/client_cert.pem"
# set a path to a root CA PEM, useful if running your own CA
#ca_file = "path/to/root_ca.pem"
# require that the server certifcate and hostname match
#verify_hostname = "true"
