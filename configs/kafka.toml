# An example configuration for benchmarking Kafka (https://kafka.apache.org/)

[general]
# specify the protocol to be used
protocol = "kafka"
# the interval for stats integration and reporting
interval = 1
# the number of intervals to run the test for
duration = 30
# optionally, we can write some detailed stats to a file during the run
metrics_output = "stats.json"
# run the admin thread with a HTTP listener at the address provided, this allows
# stats exposition via HTTP
admin = "127.0.0.1:9090"
# optionally, set an initial seed for the PRNGs used to generate the workload.
# The default is to intialize from the OS entropy pool.
#initial_seed = "0"

[debug]
# choose from: error, warn, info, debug, trace
log_level = "info"
# optionally, log to the file below instead of standard out
# log_file = "rpc-perf.log"
# backup file name for use with log rotation
log_backup = "rpc-perf.log.old"
# trigger log rotation when the file grows beyond this size (in bytes). Set this
# option to '0' to disable log rotation.
log_max_size = 1073741824

[target]
# Kafka broker ip:port
endpoints = [
  "localhost:9092"
]

[pubsub]
# Set the "socket.timeout.ms" Kafka client configuration
connect_timeout = 1000
# Set the "message.timeout.ms" Kafka client configuration
publish_timeout = 1000
# the number of threads in the publisher runtime
publisher_threads = 4
# the total number of Kafka producer clients
publisher_poolsize = 1
# the total number of Kafka producing tasks per producer client
publisher_concurrency = 20
# the number of threads in the subscriber runtime
subscriber_threads = 4
# kafka-specific client configurations
kafka_acks = "all"
kafka_linger_ms = "1"
kafka_exactly_once = false
kafka_batch_size="131072"
kafka_fetch_message_max_bytes="10485760"
kafka_compression_type="none"
#kafka_request_timeout_ms

[workload]
# the number of threads that will be used to generate requests
threads = 1

[workload.ratelimit]
# the global ratelimit
start = 1000

# An example set of
#topics using a single consumer multiple producer.
[[workload.topics]]
# the weight relative to other workload components
weight = 1
# the total number of Kafka consumer clients
subscriber_poolsize = 2
# whether the Kafka consumer clients share same consumer group
# default is false that messages are fanout to all clients
# if true, there is no fanout
kafka_same_subscriber_group = true
# the total number of Kafka tasks per Kafka consumer client
# NOTE: received messages will not fanout to all tasks per client. To compare
# with other pubsub implementations, set the concurrency to `1`,
# set the kafka_same_subscriber_group to false, and increase the
# poolsize instead.
subscriber_concurrency = 4
# the number of topics
topics = 1
# the length of the topic names, in bytes
topic_len = 7
# the topic names, if empty or the length and the number do not match topics and topic_len, generate random names
topic_names = ["rpcperf"]
# the number of partitions in each topic
partitions = 10
# the value length, in bytes
<<<<<<< HEAD
message_len = 1024
=======
message_len = 512
# optionally, specify an approximate compression ratio for the message payload.
# Defaults to 1.0 meaning the message is high-entropy and not compressible.
compression_ratio = 1.0
>>>>>>> main
# the key length, in bytes
key_len = 8
#
# To enable the TLS support, uncomment the [tls] section, add the CA file path, and
# point the endpoints in the [target] to the Kafka TLS port.
#[tls]
#  ca_file = CA_FILE_PATH
